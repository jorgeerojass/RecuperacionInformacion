{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19118f9f",
   "metadata": {},
   "source": [
    "## EXAMEN DE RECUPERACION DE LA INFORMACION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e76b96",
   "metadata": {},
   "source": [
    "### SEGUNDO BIMESTRE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c6812c",
   "metadata": {},
   "source": [
    "#### Jorge Rojas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d4745f",
   "metadata": {},
   "source": [
    "#### CARGA Y EDIT DEL CORPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed67c292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.3.12)\n",
      "Requirement already satisfied: packaging in c:\\users\\gboy2\\appdata\\roaming\\python\\python311\\site-packages (from kagglehub) (25.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kagglehub) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kagglehub) (2.32.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->kagglehub) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->kagglehub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->kagglehub) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->kagglehub) (2025.6.15)\n",
      "Requirement already satisfied: colorama in c:\\users\\gboy2\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08bee628",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gboy2\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\gboy2\\.cache\\kagglehub\\datasets\\Cornell-University\\arxiv\\versions\\244\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Descargamos el dataset\n",
    "path = kagglehub.dataset_download(\"Cornell-University/arxiv\")\n",
    "print(\"Path to dataset files:\", path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a0ffa1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documentos: 2792339\n",
      "Corpus reducido a 27923 documentos\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Cargamos el JSON\n",
    "file_path = os.path.join(path, \"arxiv-metadata-oai-snapshot.json\")  \n",
    "\n",
    "# Leer JSON \n",
    "documents = []\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        try:\n",
    "            doc = json.loads(line)\n",
    "            documents.append(doc)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "print(f\"Total documentos: {len(documents)}\")\n",
    "\n",
    "# Tomar solo el 1%\n",
    "subset_size = int(len(documents) * 0.01)\n",
    "subset = random.sample(documents, subset_size)\n",
    "\n",
    "print(f\"Corpus reducido a {len(subset)} documentos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c235f424",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"arxiv_subset.json\", \"w\", encoding=\"utf-8\") as out:\n",
    "    json.dump(subset, out, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5894667",
   "metadata": {},
   "source": [
    "#### PREPROCESAMIENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c83f5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\gboy2/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gboy2/nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # minúsculas\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # eliminar puntuación\n",
    "    tokens = word_tokenize(text)  # tokenización\n",
    "    tokens = [word for word in tokens if word not in stop_words]  # quitar stopwords\n",
    "    return \" \".join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6f1db44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\gboy2/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6b4cd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.data.path.append(\"C:/Users/gboy2/nltk_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a846197",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\gboy2/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Borra manualmente si no lo hiciste antes\n",
    "shutil.rmtree(\"C:/Users/gboy2/nltk_data/tokenizers/punkt\", ignore_errors=True)\n",
    "\n",
    "# Fuerza nueva descarga\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af982e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\gboy2/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76b61e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "def preprocess_fallback(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "    tokens = text.split()\n",
    "    return \" \".join([t for t in tokens if t not in ENGLISH_STOP_WORDS])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29dc74ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Corpus cargado con 27923 documentos\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"arxiv_subset.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    subset = json.load(f)\n",
    "\n",
    "print(f\" Corpus cargado con {len(subset)} documentos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef10f3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "processed_docs = []\n",
    "for doc in subset:\n",
    "    combined_text = doc[\"title\"] + \" \" + doc[\"abstract\"]\n",
    "    processed = preprocess_fallback(combined_text)  # usamos la versión sin NLTK\n",
    "    processed_docs.append(processed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "433d7ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = []\n",
    "for doc in subset:\n",
    "    combined_text = doc[\"title\"] + \" \" + doc[\"abstract\"]\n",
    "    processed = preprocess_fallback(combined_text)\n",
    "    processed_docs.append(processed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bb5f209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "def preprocess_fallback(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text.lower())  # quitar puntuación y pasar a minúsculas\n",
    "    tokens = text.split()\n",
    "    return \" \".join([t for t in tokens if t not in ENGLISH_STOP_WORDS])  # eliminar stopwords\n",
    "\n",
    "# Inicializar listas\n",
    "processed_docs = []\n",
    "doc_ids = []\n",
    "titles = []\n",
    "abstracts = []\n",
    "\n",
    "# Procesar documentos\n",
    "for doc in subset:\n",
    "    if \"title\" in doc and \"abstract\" in doc:\n",
    "        combined = f\"{doc['title']} {doc['abstract']}\"\n",
    "        cleaned = preprocess_fallback(combined)\n",
    "        processed_docs.append(cleaned)\n",
    "        doc_ids.append(doc[\"id\"])\n",
    "        titles.append(doc[\"title\"])\n",
    "        abstracts.append(doc[\"abstract\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66db5281",
   "metadata": {},
   "source": [
    "#### INDEXACION TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26489460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " TF-IDF generado: 27923 documentos, 123169 términos únicos\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Crear el vectorizador\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Aplicar sobre los textos procesados\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(processed_docs)\n",
    "\n",
    "print(f\" TF-IDF generado: {tfidf_matrix.shape[0]} documentos, {tfidf_matrix.shape[1]} términos únicos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0c49b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tfidf(query, top_k=10):\n",
    "    query_cleaned = preprocess_text(query)\n",
    "    query_vec = tfidf_vectorizer.transform([query_cleaned])\n",
    "    scores = (tfidf_matrix @ query_vec.T).toarray().flatten()\n",
    "    top_indices = scores.argsort()[::-1][:top_k]\n",
    "    \n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        results.append({\n",
    "            \"id\": doc_ids[idx],\n",
    "            \"title\": titles[idx],\n",
    "            \"score\": scores[idx],\n",
    "            \"abstract_snippet\": abstracts[idx][:300] + \"...\"\n",
    "        })\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa0a0a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Crear vectorizador y ajustar\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(processed_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51d17529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tfidf(query, top_k=10):\n",
    "    query_clean = preprocess_fallback(query)  # usamos el mismo limpiador\n",
    "    query_vec = tfidf_vectorizer.transform([query_clean])\n",
    "    scores = (tfidf_matrix @ query_vec.T).toarray().flatten()\n",
    "    top_indices = scores.argsort()[::-1][:top_k]\n",
    "    \n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        results.append({\n",
    "            \"id\": doc_ids[idx],\n",
    "            \"title\": titles[idx],\n",
    "            \"score\": round(scores[idx], 4),\n",
    "            \"abstract_snippet\": abstracts[idx][:300] + \"...\"\n",
    "        })\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a44139",
   "metadata": {},
   "source": [
    "##### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03a6e626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 The Hybrid Monte Carlo Algorithm for Quantum Chromodynamics (Score: 0.3405)\n",
      "   The Hybrid Monte Carlo (HMC) algorithm currently is the favorite scheme to\n",
      "simulate quantum chromodynamics including dynamical fermions. In this\n",
      "talk-which is intended for a non-expert audience--I want to bring together\n",
      "methodical and practical aspects of the HMC for full QCD simulations. I will\n",
      "c...\n",
      "\n",
      "🔹 Simulating quantum field theory with a quantum computer (Score: 0.2618)\n",
      "   Forthcoming exascale digital computers will further advance our knowledge of\n",
      "quantum chromodynamics, but formidable challenges will remain. In particular,\n",
      "Euclidean Monte Carlo methods are not well suited for studying real-time\n",
      "evolution in hadronic collisions, or the properties of hadronic matter...\n",
      "\n",
      "🔹 Quantum Fisher information as the measure of Gaussian quantum\n",
      "  correlation: Role in quantum metrology (Score: 0.2243)\n",
      "   We have introduced a measure of Gaussian quantum correlations based on\n",
      "quantum Fisher information. For bipartite Gaussian states the minimum quantum\n",
      "Fisher information due to local unitary evolution on one of the parties\n",
      "reliably quantifies quantum correlation. In quantum metrology the proposed\n",
      "me...\n",
      "\n",
      "🔹 An Axiomatization for Quantum Processes to Unifying Quantum and\n",
      "  Classical Computing (Score: 0.2059)\n",
      "   We establish an axiomatization for quantum processes, which is a quantum\n",
      "generalization of process algebra ACP (Algebra of Communicating Processes). We\n",
      "use the framework of a quantum process configuration $\\langle p,\n",
      "\\varrho\\rangle$, but we treat it as two relative independent part: the\n",
      "structural...\n",
      "\n",
      "🔹 Searching for quantum speedup in quasistatic quantum annealers (Score: 0.2028)\n",
      "   We argue that a quantum annealer at very long annealing times is likely to\n",
      "experience a quasistatic evolution, returning a final population that is close\n",
      "to a Boltzmann distribution of the Hamiltonian at a single (freeze-out) point\n",
      "during the annealing. Such a system is expected to correlate well ...\n",
      "\n",
      "🔹 A Full Quantum Eigensolver for Quantum Chemistry Simulations (Score: 0.1993)\n",
      "   Quantum simulation of quantum chemistry is one of the most compelling\n",
      "applications of quantum computing. It is of particular importance in areas\n",
      "ranging from materials science, biochemistry and condensed matter physics.\n",
      "Here, we propose a full quantum eigensolver (FQE) algorithm to calculate the\n",
      "m...\n",
      "\n",
      "🔹 Quantifying Quantum Steering with Limited Resources: A Semi-supervised\n",
      "  Machine Learning Approach (Score: 0.198)\n",
      "   Quantum steering, an intermediate quantum correlation lying between\n",
      "entanglement and nonlocality, has emerged as a critical quantum resource for a\n",
      "variety of quantum information processing tasks such as quantum key\n",
      "distribution and true randomness generation. The ability to detect and quantify\n",
      "qua...\n",
      "\n",
      "🔹 Quantum memory for images - a quantum hologram (Score: 0.1971)\n",
      "   Matter-light quantum interface and quantum memory for light are important\n",
      "ingredients of quantum information protocols, such as quantum networks,\n",
      "distributed quantum computation, etc. In this Letter we present a spatially\n",
      "multimode scheme for quantum memory for light, which we call a quantum\n",
      "holog...\n",
      "\n",
      "🔹 Relative entropy in quantum information theory (Score: 0.1971)\n",
      "   We review the properties of the quantum relative entropy function and discuss\n",
      "its application to problems of classical and quantum information transfer and\n",
      "to quantum data compression. We then outline further uses of relative entropy\n",
      "to quantify quantum entanglement and analyze its manipulation.\n",
      "...\n",
      "\n",
      "🔹 Enhancing Generative Models via Quantum Correlations (Score: 0.1966)\n",
      "   Generative modeling using samples drawn from the probability distribution\n",
      "constitutes a powerful approach for unsupervised machine learning. Quantum\n",
      "mechanical systems can produce probability distributions that exhibit quantum\n",
      "correlations which are difficult to capture using classical models. We ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"quantum chromodynamics\"\n",
    "results = search_tfidf(query)\n",
    "\n",
    "for r in results:\n",
    "    print(f\"🔹 {r['title']} (Score: {r['score']})\")\n",
    "    print(f\" {r['abstract_snippet']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd6fe2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rank_bm25 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rank_bm25) (2.2.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b1404e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_tokenize(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "    return [t for t in text.split() if t not in ENGLISH_STOP_WORDS]\n",
    "\n",
    "tokenized_docs = [simple_tokenize(doc) for doc in processed_docs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f3d4d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "bm25_model = BM25Okapi(tokenized_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74e48d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_bm25(query, top_k=10):\n",
    "    query_tokens = simple_tokenize(query)\n",
    "    scores = bm25_model.get_scores(query_tokens)\n",
    "    top_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:top_k]\n",
    "\n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        results.append({\n",
    "            \"id\": doc_ids[idx],\n",
    "            \"title\": titles[idx],\n",
    "            \"score\": round(scores[idx], 4),\n",
    "            \"abstract_snippet\": abstracts[idx][:300] + \"...\"\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f2f4bd",
   "metadata": {},
   "source": [
    "##### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98d8fc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 The Hybrid Monte Carlo Algorithm for Quantum Chromodynamics (Score: 15.32)\n",
      "   The Hybrid Monte Carlo (HMC) algorithm currently is the favorite scheme to\n",
      "simulate quantum chromodynamics including dynamical fermions. In this\n",
      "talk-which is intended for a non-expert audience--I want to bring together\n",
      "methodical and practical aspects of the HMC for full QCD simulations. I will\n",
      "c...\n",
      "\n",
      "🔹 Simulating quantum field theory with a quantum computer (Score: 11.68)\n",
      "   Forthcoming exascale digital computers will further advance our knowledge of\n",
      "quantum chromodynamics, but formidable challenges will remain. In particular,\n",
      "Euclidean Monte Carlo methods are not well suited for studying real-time\n",
      "evolution in hadronic collisions, or the properties of hadronic matter...\n",
      "\n",
      "🔹 Instanton infra-red stabilization in the nonperturbative QCD vacuum (Score: 11.47)\n",
      "   The influence of nonperturbative fields on instantons in quantum\n",
      "chromodynamics is studied. Nonperturbative vacuum is described in terms of\n",
      "nonlocal gauge invariant vacuum averages of gluon field strength. Effective\n",
      "action for instanton is derived in bilocal approximation and it is demonstrated\n",
      "th...\n",
      "\n",
      "🔹 On confined fractional charges: a simple model (Score: 10.85)\n",
      "   We address the question whether features known from quantum chromodynamics\n",
      "(QCD) can possibly also show up in solid-state physics. It is shown that\n",
      "spinless fermions of charge $e$ on a checkerboard lattice with nearest-neighbor\n",
      "repulsion provide for a simple model of confined fractional charges. A...\n",
      "\n",
      "🔹 Lowest Dimensional Portals to SU($N$) Exotics (Score: 10.53)\n",
      "   New matter fields charged under the strong nuclear force would have dramatic\n",
      "phenomenological implications. Here, we systematically explore how these new\n",
      "states, which we postulate belong to some representation of SU(3) of quantum\n",
      "chromo-dynamics, could interact with Standard Model fields: We anal...\n",
      "\n",
      "🔹 D-meson production in the GM-VFN scheme (Score: 10.41)\n",
      "   We study the inclusive hadrodroduction of D^0, D^+, D^{*+}, and D_s^+ mesons\n",
      "at next-to-leading order in the parton model of quantum chromodynamics endowed\n",
      "with universal non-perturbative fragmentation functions (FFs) fitted to e^+e^-\n",
      "annihilation data from CERN LEP1. Working in the general-mass\n",
      "v...\n",
      "\n",
      "🔹 The O(\\alpha_s^3) Heavy Flavor Contributions to the Charged Current\n",
      "  Structure Function xF_3(x,Q^2) at Large Momentum Transfer (Score: 10.06)\n",
      "   We calculate the massive Wilson coefficients for the heavy flavor\n",
      "contributions to the non-singlet charged current deep-inelastic scattering\n",
      "structure function $xF_3^{W^+}(x,Q^2)+xF_3^{W^-}(x,Q^2)$ in the asymptotic\n",
      "region $Q^2 \\gg m^2$ to 3-loop order in Quantum Chromodynamics (QCD) at general\n",
      "va...\n",
      "\n",
      "🔹 The string model of the Cooper pair in the anisotropic superconductor (Score: 10.00)\n",
      "   The analogy between the Cooper pair in high temperature superconductor and\n",
      "the quark-antiquark pair in quantum chromodynamics (QCD) is proposed. In QCD\n",
      "the nonlinear chromodynamical field between a quark and an antiquark is\n",
      "confined to a tube. So we assume that there is the strong interaction betw...\n",
      "\n",
      "🔹 Gluon fragmentation function in polarised $\\Lambda$ hyperon production:\n",
      "  The Method of Factorisation (Score: 10.00)\n",
      "   We discuss the polarised fragmentation functions of quarks and gluons in\n",
      "Perturbative Quantum Chromodynamics. The Altarelli-Parisi evolution equations\n",
      "governing these fragmentation functions are presented. We find that the first\n",
      "moment of the polarised gluon fragmentation function to order $\\alpha...\n",
      "\n",
      "🔹 On a novel evalutation of the hadronic contribution to the muon's $g-2$\n",
      "  from QCD (Score: 9.89)\n",
      "   We evaluate the hadronic contribution to the $g-2$ of the muon by deriving\n",
      "the low-energy limit of quantum chromodynamics (QCD) and computing in this way\n",
      "the hadronic vacuum polarization. The low-energy limit is a non-local\n",
      "Nambu--Jona-Lasinio (NJL) model that has all the parameters fixed from QCD...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"quantum chromodynamics\"\n",
    "results = search_bm25(query)\n",
    "\n",
    "for r in results:\n",
    "    print(f\"🔹 {r['title']} (Score: {r['score']:.2f})\")\n",
    "    print(f\" {r['abstract_snippet']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3364a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.11.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (4.53.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (1.7.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (0.33.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (11.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\gboy2\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (4.14.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from faiss-cpu) (2.2.6)\n",
      "Requirement already satisfied: packaging in c:\\users\\gboy2\\appdata\\roaming\\python\\python311\\site-packages (from faiss-cpu) (25.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.5.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\gboy2\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.6.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install sentence-transformers faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "411cd5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 873/873 [08:37<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " FAISS cargado con 27923 documentos\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "# Cargar modelo\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Generar embeddings del corpus\n",
    "corpus_embeddings = embedding_model.encode(processed_docs, show_progress_bar=True)\n",
    "\n",
    "# Crear índice FAISS (distancia L2)\n",
    "dimension = corpus_embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(np.array(corpus_embeddings))\n",
    "\n",
    "print(\" FAISS cargado con\", index.ntotal, \"documentos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b44941a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_faiss(query, top_k=10):\n",
    "    query_vec = embedding_model.encode([query])\n",
    "    D, I = index.search(np.array(query_vec), top_k)\n",
    "\n",
    "    results = []\n",
    "    for idx in I[0]:\n",
    "        results.append({\n",
    "            \"id\": doc_ids[idx],\n",
    "            \"title\": titles[idx],\n",
    "            \"score\": round(D[0][list(I[0]).index(idx)], 4),\n",
    "            \"abstract_snippet\": abstracts[idx][:300] + \"...\"\n",
    "        })\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6618c6",
   "metadata": {},
   "source": [
    "##### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa581015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 The Aharonov-Anandan phase of a classical dynamical system seen\n",
      "  mathematically as a quantum dynamical system (Distancia: 0.9886000156402588)\n",
      "   It is shown that the non-adiabatic Hannay's angle of an integrable\n",
      "non-degenerate classical hamiltonian dynamical system may be related to the\n",
      "Aharonov-Anandan phase it develops when it is looked mathematically as a\n",
      "quantum dynamical system.\n",
      "...\n",
      "\n",
      "🔹 The Second Law of Thermodynamics under Unitary Evolution and External\n",
      "  Operations (Distancia: 1.0778000354766846)\n",
      "   A microscopic definition of the thermodynamic entropy in an isolated quantum\n",
      "system must satisfy (i) additivity, (ii) extensivity and (iii) the second law\n",
      "of thermodynamics. We show that the diagonal entropy, which is the Shannon\n",
      "entropy in the energy eigenbasis at each instant of time, meets the ...\n",
      "\n",
      "🔹 Triple Interference, Non-linear Talbot Effect and Gravitization of the\n",
      "  Quantum (Distancia: 1.0785000324249268)\n",
      "   Recently we have discussed a new approach to the problem of quantum gravity\n",
      "in which the quantum mechanical structures that are traditionally fixed, such\n",
      "as the Fubini-Study metric in the Hilbert space of states, become dynamical and\n",
      "so implement the idea of gravitizing the quantum. In this paper ...\n",
      "\n",
      "🔹 Classical stochastic approach to quantum mechanics and quantum\n",
      "  thermodynamics (Distancia: 1.0793999433517456)\n",
      "   We derive the equations of quantum mechanics and quantum thermodynamics from\n",
      "the assumption that a quantum system can be described by an underlying\n",
      "classical system of particles. Each component $\\phi_j$ of the wave vector is\n",
      "understood as a stochastic complex variable whose real and imaginary part...\n",
      "\n",
      "🔹 Defect production in nonequilibrium phase transitions: Experimental\n",
      "  investigation of the Kibble-Zurek mechanism in a two-qubit quantum simulator (Distancia: 1.0800000429153442)\n",
      "   Systems passing through quantum critical points at finite rates have a finite\n",
      "probability of undergoing transitions between different eigenstates of the\n",
      "instantaneous Hamiltonian. This mechanism was proposed by Kibble as the\n",
      "underlying mechanism for the formation of topological defects in the earl...\n",
      "\n",
      "🔹 Oriented Quantum Algebras and Coalgebras, Invariants of Oriented 1-1\n",
      "  Tangles, Knots and Links (Distancia: 1.0898000001907349)\n",
      "   In this paper we study oriented quantum coalgebras which are structures\n",
      "closely related to oriented quantum algebras. We study the relationship between\n",
      "oriented quantum coalgebras and oriented quantum algebras and the relationship\n",
      "between oriented quantum coalgebras and quantum coalgebras. We show...\n",
      "\n",
      "🔹 A new duality between Topological M-theory and Loop Quantum Gravity (Distancia: 1.093999981880188)\n",
      "   Inspired by the long wave-length limit of topological M-theory, which\n",
      "re-constructs the theory of $3+1$D gravity in the self-dual variables'\n",
      "formulation, we conjecture the existence of a duality between Hilbert spaces,\n",
      "the ${\\bf H}$-duality, to unify topological M-theory and loop quantum gravity\n",
      "(...\n",
      "\n",
      "🔹 Equation of State of Quantum Gases Beyond the Van der Waals\n",
      "  Approximation (Distancia: 1.0995999574661255)\n",
      "   A recently suggested equation of state with the induced surface tension is\n",
      "generalized to the case of quantum gases with mean-field interaction. The\n",
      "self-consistency conditions of such a model and the necessary one to obey the\n",
      "Third Law of thermodynamics are found. The quantum virial expansion of ...\n",
      "\n",
      "🔹 The Maxwell-Bloch Theory in Quantum Optics and the Kondo Model (Distancia: 1.1033999919891357)\n",
      "   In this letter, the problem of radiation in a fiber geometry interacting with\n",
      "a two level atom is mapped onto the anisotropic Kondo model. Thermodynamical\n",
      "and dynamical properties are then computed exploiting the integrability of this\n",
      "latter system. We compute some correlation functions, decay rat...\n",
      "\n",
      "🔹 Orthogonal Quantum Group Invariants of Links (Distancia: 1.115399956703186)\n",
      "   We study the Chern-Simons partition function of orthogonal quantum group\n",
      "invariants, and propose a new orthogonal Labastida-Mari\\~{n}o-Ooguri-Vafa\n",
      "conjecture as well as degree conjecture for free energy associated to the\n",
      "orthogonal Chern-Simons partition function. We prove the degree conjecture an...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = search_faiss(\"quantum chromodynamics\")\n",
    "for r in results:\n",
    "    print(f\"🔹 {r['title']} (Distancia: {r['score']})\")\n",
    "    print(f\" {r['abstract_snippet']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35284eb8",
   "metadata": {},
   "source": [
    "#### EVALUACION ENTRE MODELOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79deaf66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Coincidencias en Top-10:\n",
      "TF-IDF & BM25: 2\n",
      "TF-IDF & FAISS: 0\n",
      "BM25 & FAISS: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>TF-IDF_ID</th>\n",
       "      <th>BM25_ID</th>\n",
       "      <th>FAISS_ID</th>\n",
       "      <th>TFIDF == BM25</th>\n",
       "      <th>TFIDF == FAISS</th>\n",
       "      <th>BM25 == FAISS</th>\n",
       "      <th>TFIDF_Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>hep-lat/9712019</td>\n",
       "      <td>hep-lat/9712019</td>\n",
       "      <td>math-ph/0511087</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>The Hybrid Monte Carlo Algorithm for Quantum C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1811.10085</td>\n",
       "      <td>1811.10085</td>\n",
       "      <td>1303.5471</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Simulating quantum field theory with a quantum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1406.5144</td>\n",
       "      <td>hep-ph/0211139</td>\n",
       "      <td>2303.15645</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Quantum Fisher information as the measure of G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1311.2960</td>\n",
       "      <td>cond-mat/0604666</td>\n",
       "      <td>2309.01851</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>An Axiomatization for Quantum Processes to Uni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1503.04216</td>\n",
       "      <td>2010.05827</td>\n",
       "      <td>1609.02265</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Searching for quantum speedup in quasistatic q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1908.07927</td>\n",
       "      <td>hep-ph/0608122</td>\n",
       "      <td>1004.1214</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>A Full Quantum Eigensolver for Quantum Chemist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2501.10747</td>\n",
       "      <td>1508.01449</td>\n",
       "      <td>1707.05347</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Quantifying Quantum Steering with Limited Reso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0704.1737</td>\n",
       "      <td>supr-con/9510001</td>\n",
       "      <td>1704.06846</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Quantum memory for images - a quantum hologram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>quant-ph/0004045</td>\n",
       "      <td>hep-ph/9606272</td>\n",
       "      <td>hep-th/9701022</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Relative entropy in quantum information theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2101.08354</td>\n",
       "      <td>2109.05041</td>\n",
       "      <td>1007.1656</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Enhancing Generative Models via Quantum Correl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank         TF-IDF_ID           BM25_ID         FAISS_ID  TFIDF == BM25  \\\n",
       "0     1   hep-lat/9712019   hep-lat/9712019  math-ph/0511087           True   \n",
       "1     2        1811.10085        1811.10085        1303.5471           True   \n",
       "2     3         1406.5144    hep-ph/0211139       2303.15645          False   \n",
       "3     4         1311.2960  cond-mat/0604666       2309.01851          False   \n",
       "4     5        1503.04216        2010.05827       1609.02265          False   \n",
       "5     6        1908.07927    hep-ph/0608122        1004.1214          False   \n",
       "6     7        2501.10747        1508.01449       1707.05347          False   \n",
       "7     8         0704.1737  supr-con/9510001       1704.06846          False   \n",
       "8     9  quant-ph/0004045    hep-ph/9606272   hep-th/9701022          False   \n",
       "9    10        2101.08354        2109.05041        1007.1656          False   \n",
       "\n",
       "   TFIDF == FAISS  BM25 == FAISS  \\\n",
       "0           False          False   \n",
       "1           False          False   \n",
       "2           False          False   \n",
       "3           False          False   \n",
       "4           False          False   \n",
       "5           False          False   \n",
       "6           False          False   \n",
       "7           False          False   \n",
       "8           False          False   \n",
       "9           False          False   \n",
       "\n",
       "                                         TFIDF_Title  \n",
       "0  The Hybrid Monte Carlo Algorithm for Quantum C...  \n",
       "1  Simulating quantum field theory with a quantum...  \n",
       "2  Quantum Fisher information as the measure of G...  \n",
       "3  An Axiomatization for Quantum Processes to Uni...  \n",
       "4  Searching for quantum speedup in quasistatic q...  \n",
       "5  A Full Quantum Eigensolver for Quantum Chemist...  \n",
       "6  Quantifying Quantum Steering with Limited Reso...  \n",
       "7     Quantum memory for images - a quantum hologram  \n",
       "8     Relative entropy in quantum information theory  \n",
       "9  Enhancing Generative Models via Quantum Correl...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ejecutar búsqueda con una misma query\n",
    "query = \"quantum chromodynamics\"\n",
    "tfidf_results = search_tfidf(query, top_k=10)\n",
    "bm25_results = search_bm25(query, top_k=10)\n",
    "faiss_results = search_faiss(query, top_k=10)\n",
    "\n",
    "# Extraer IDs\n",
    "tfidf_ids = [doc[\"id\"] for doc in tfidf_results]\n",
    "bm25_ids = [doc[\"id\"] for doc in bm25_results]\n",
    "faiss_ids = [doc[\"id\"] for doc in faiss_results]\n",
    "\n",
    "# Comparativa por ranking\n",
    "df = pd.DataFrame({\n",
    "    \"Rank\": range(1, 11),\n",
    "    \"TF-IDF_ID\": tfidf_ids,\n",
    "    \"BM25_ID\": bm25_ids,\n",
    "    \"FAISS_ID\": faiss_ids\n",
    "})\n",
    "\n",
    "# Coincidencias por posición\n",
    "df[\"TFIDF == BM25\"] = df[\"TF-IDF_ID\"] == df[\"BM25_ID\"]\n",
    "df[\"TFIDF == FAISS\"] = df[\"TF-IDF_ID\"] == df[\"FAISS_ID\"]\n",
    "df[\"BM25 == FAISS\"] = df[\"BM25_ID\"] == df[\"FAISS_ID\"]\n",
    "\n",
    "# Coincidencias globales \n",
    "intersection_tf_bm25 = len(set(tfidf_ids) & set(bm25_ids))\n",
    "intersection_tf_faiss = len(set(tfidf_ids) & set(faiss_ids))\n",
    "intersection_bm25_faiss = len(set(bm25_ids) & set(faiss_ids))\n",
    "\n",
    "print(\" Coincidencias en Top-10:\")\n",
    "print(f\"TF-IDF & BM25: {intersection_tf_bm25}\")\n",
    "print(f\"TF-IDF & FAISS: {intersection_tf_faiss}\")\n",
    "print(f\"BM25 & FAISS: {intersection_bm25_faiss}\")\n",
    "\n",
    "df[\"TFIDF_Title\"] = [doc[\"title\"] for doc in tfidf_results] # Modelo base del documento en TF-IDFF\n",
    "\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ec649c",
   "metadata": {},
   "source": [
    "#### RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "00cf092b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.97.1)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\gboy2\\appdata\\roaming\\python\\python311\\site-packages (from openai) (4.14.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\gboy2\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "791fb525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key cargada: Sí\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai  # ✅ IMPORTAR EL MÓDULO OPENAI\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Verifica (opcional):\n",
    "print(\"API Key cargada:\", \"Sí\" if openai.api_key else \"No\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "970de1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.97.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\gboy2\\appdata\\roaming\\python\\python311\\site-packages (from openai) (4.14.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\gboy2\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d7fde8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Cargar clave desde .env\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def generate_rag_response_openai(query, top_k=3):\n",
    "    top_docs = search_faiss(query, top_k=top_k)\n",
    "    contexto = \"\\n\\n\".join([f\"{i+1}. {doc['abstract_snippet']}\" for i, doc in enumerate(top_docs)])\n",
    "\n",
    "    prompt = (\n",
    "        f\"Pregunta del usuario:\\n{query}\\n\\n\"\n",
    "        f\"Contexto recuperado desde documentos científicos relevantes:\\n{contexto}\\n\\n\"\n",
    "        f\"Con base en el contexto anterior, responde de forma clara, concisa y académica:\"\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a8e2ee85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum Chromodynamics (QCD) es la teoría cuántica de los campos que describe la interacción fuerte entre quarks y gluones, los constituyentes fundamentales de los hadrones como los protones y neutrones. Esta teoría es parte del Modelo Estándar de la física de partículas y se encarga de explicar fenómenos como la confinamiento de los quarks, la cromodinámica de los gluones y la estructura interna de los hadrones. En el contexto de la física cuántica, QCD es fundamental para comprender las interacciones a nivel subatómico y ha sido objeto de numerosos estudios teóricos y experimentales en el campo de la física de partículas.\n"
     ]
    }
   ],
   "source": [
    "print(generate_rag_response_openai(\"quantum chromodynamics\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41add8b3",
   "metadata": {},
   "source": [
    "##### EVALUACION Y TEST SI LA RESPUESTA USA LA INFORMACION DEL CONTEXTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "52263b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def evaluar_rag_response(query, top_k=3):\n",
    "    # 1. Obtener documentos\n",
    "    top_docs = search_faiss(query, top_k=top_k)\n",
    "    context = \" \".join([doc[\"abstract_snippet\"] for doc in top_docs])\n",
    "\n",
    "    # 2. Generar respuesta\n",
    "    respuesta = generate_rag_response_openai(query, top_k=top_k)\n",
    "\n",
    "    # 3. Palabras clave del contexto\n",
    "    context_tokens = [t for t in re.sub(r'[^\\w\\s]', '', context.lower()).split() if t not in ENGLISH_STOP_WORDS]\n",
    "    respuesta_tokens = [t for t in re.sub(r'[^\\w\\s]', '', respuesta.lower()).split()]\n",
    "\n",
    "    # 4. Comparar y contar coincidencias\n",
    "    context_counter = Counter(context_tokens)\n",
    "    respuesta_counter = Counter(respuesta_tokens)\n",
    "    coincidencias = sum((respuesta_counter & context_counter).values())\n",
    "\n",
    "    print(\"Consulta:\", query)\n",
    "    print(\"Palabras clave del contexto:\", len(set(context_tokens)))\n",
    "    print(\"Palabras en respuesta:\", len(respuesta_tokens))\n",
    "    print(\"Palabras del contexto usadas en la respuesta:\", coincidencias)\n",
    "    print(\"\\n Respuesta generada:\")\n",
    "    print(respuesta)\n",
    "\n",
    "    return {\n",
    "        \"coincidencias\": coincidencias,\n",
    "        \"longitud_contexto\": len(set(context_tokens)),\n",
    "        \"longitud_respuesta\": len(respuesta_tokens),\n",
    "        \"respuesta\": respuesta\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3377ed78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consulta: quantum chromodynamics\n",
      "Palabras clave del contexto: 55\n",
      "Palabras en respuesta: 84\n",
      "Palabras del contexto usadas en la respuesta: 1\n",
      "\n",
      " Respuesta generada:\n",
      "Quantum Chromodynamics (QCD) es una teoría fundamental de las interacciones fuertes entre quarks y gluones, que son los constituyentes fundamentales de los protones, neutrones y otras partículas subatómicas. En el marco de la física de partículas, QCD describe cómo los quarks y gluones interactúan a través de la fuerza nuclear fuerte, que es mediada por los gluones. Esta teoría es crucial para entender la estructura de los hadrones y fenómenos como la cromodinámica cuántica confinamiento de los quarks dentro de los protones y neutrones.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'coincidencias': 1,\n",
       " 'longitud_contexto': 55,\n",
       " 'longitud_respuesta': 84,\n",
       " 'respuesta': 'Quantum Chromodynamics (QCD) es una teoría fundamental de las interacciones fuertes entre quarks y gluones, que son los constituyentes fundamentales de los protones, neutrones y otras partículas subatómicas. En el marco de la física de partículas, QCD describe cómo los quarks y gluones interactúan a través de la fuerza nuclear fuerte, que es mediada por los gluones. Esta teoría es crucial para entender la estructura de los hadrones y fenómenos como la cromodinámica cuántica confinamiento de los quarks dentro de los protones y neutrones.'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluar_rag_response(\"quantum chromodynamics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccf2eea",
   "metadata": {},
   "source": [
    "#### CONSULTAS queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "71b80c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Consulta: diphoton production cross sections\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "🔹 TF-IDF - Top 10 documentos:\n",
      "1. 1704.08903 - Status and challenges of neutrino cross sections...\n",
      "2. nucl-ex/0702050 - Projectile fragmentation reactions and production of nuclei ...\n",
      "3. nucl-th/0605051 - Random Phase Approximation and neutrino-nucleus cross sectio...\n",
      "4. 1701.04866 - Cosmic Ray Antiprotons at High Energies...\n",
      "5. 1603.09354 - Asymmetric Dark Matter Models and the LHC Diphoton Excess...\n",
      "6. 1510.00299 - Imaging resonances in low-energy NO-He inelastic collisions...\n",
      "7. 0808.1625 - Exclusive heavy quarkonium + gamma production from e+ e- ann...\n",
      "8. hep-ph/0111078 - Prospects for New Physics observations in diffractive proces...\n",
      "9. nucl-ex/9810016 - Measurement of the 6Li(e,e'p) reaction cross sections at low...\n",
      "10. 0804.0490 - Photon plus Jet Cross Sections at the Tevatron...\n",
      "\n",
      "🔹 BM25 - Top 10 documentos:\n",
      "1. 0804.0490 - Photon plus Jet Cross Sections at the Tevatron...\n",
      "2. nucl-ex/0702050 - Projectile fragmentation reactions and production of nuclei ...\n",
      "3. 1701.04866 - Cosmic Ray Antiprotons at High Energies...\n",
      "4. hep-ph/0407193 - Central inclusive dijets production by double pomeron exchan...\n",
      "5. 1704.08903 - Status and challenges of neutrino cross sections...\n",
      "6. 0808.1625 - Exclusive heavy quarkonium + gamma production from e+ e- ann...\n",
      "7. hep-ph/0111078 - Prospects for New Physics observations in diffractive proces...\n",
      "8. 1906.02185 - Near-threshold $\\eta^\\prime$ meson production in ${\\pi^-}A$ ...\n",
      "9. hep-ph/9205201 - Production of the Lightest Supersymmetric Particle in Electr...\n",
      "10. 1203.1170 - Measurement of Inclusive and Dijet D* Meson Cross Sections i...\n",
      "\n",
      "🔹 FAISS - Top 10 documentos:\n",
      "1. 1607.03076 - The Observed Diphoton Excess in F-theory Inspired Heterotic\n",
      "...\n",
      "2. 0712.3913 - Initial-state showering based on colour dipoles connected to...\n",
      "3. 2504.12837 - Dipole-pion cross section in the saturation regime...\n",
      "4. hep-ph/0407193 - Central inclusive dijets production by double pomeron exchan...\n",
      "5. 1511.01288 - Target Studies for Surface Muon Production...\n",
      "6. hep-ph/9711250 - Photoproduction Processes in Polarized ep - Collisions at HE...\n",
      "7. 1512.06842 - One jet to rule them all: monojet constraints and invisible ...\n",
      "8. nucl-th/9510057 - Quasifree Pion Electroproduction from Nuclei in the $\\Delta$...\n",
      "9. hep-ph/0407346 - Inclusive cross-sections for jet production in nucleus-nucle...\n",
      "10. hep-ex/0510009 - Inclusive production of charged pions in p+p collisions at 1...\n",
      "\n",
      " Comparación de coincidencias en el top 10:\n",
      "TF-IDF vs BM25: 6 en común → ['0808.1625', '1704.08903', '1701.04866', 'nucl-ex/0702050', '0804.0490', 'hep-ph/0111078']\n",
      "TF-IDF vs FAISS: 0 en común → []\n",
      "BM25 vs FAISS: 1 en común → ['hep-ph/0407193']\n",
      "\n",
      " Respuesta generada por RAG (CHAT GTP):\n",
      "Las secciones eficaces de producción de diphoton se refieren a la probabilidad de que se genere un par de fotones en una colisión de partículas. Estas secciones eficaces son importantes para estudiar procesos físicos como la producción y desintegración de partículas en experimentos de alta energía, como los realizados en el LHC. La observación de un exceso de diphoton en el LHC ha motivado investigaciones teóricas y experimentales para comprender mejor este fenómeno y sus implicaciones en la física de partículas.\n",
      "\n",
      "========================================================================================================================\n",
      "\n",
      " Consulta: quantum chromodynamics\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "🔹 TF-IDF - Top 10 documentos:\n",
      "1. hep-lat/9712019 - The Hybrid Monte Carlo Algorithm for Quantum Chromodynamics...\n",
      "2. 1811.10085 - Simulating quantum field theory with a quantum computer...\n",
      "3. 1406.5144 - Quantum Fisher information as the measure of Gaussian quantu...\n",
      "4. 1311.2960 - An Axiomatization for Quantum Processes to Unifying Quantum ...\n",
      "5. 1503.04216 - Searching for quantum speedup in quasistatic quantum anneale...\n",
      "6. 1908.07927 - A Full Quantum Eigensolver for Quantum Chemistry Simulations...\n",
      "7. 2501.10747 - Quantifying Quantum Steering with Limited Resources: A Semi-...\n",
      "8. 0704.1737 - Quantum memory for images - a quantum hologram...\n",
      "9. quant-ph/0004045 - Relative entropy in quantum information theory...\n",
      "10. 2101.08354 - Enhancing Generative Models via Quantum Correlations...\n",
      "\n",
      "🔹 BM25 - Top 10 documentos:\n",
      "1. hep-lat/9712019 - The Hybrid Monte Carlo Algorithm for Quantum Chromodynamics...\n",
      "2. 1811.10085 - Simulating quantum field theory with a quantum computer...\n",
      "3. hep-ph/0211139 - Instanton infra-red stabilization in the nonperturbative QCD...\n",
      "4. cond-mat/0604666 - On confined fractional charges: a simple model...\n",
      "5. 2010.05827 - Lowest Dimensional Portals to SU($N$) Exotics...\n",
      "6. hep-ph/0608122 - D-meson production in the GM-VFN scheme...\n",
      "7. 1508.01449 - The O(\\alpha_s^3) Heavy Flavor Contributions to the Charged ...\n",
      "8. supr-con/9510001 - The string model of the Cooper pair in the anisotropic super...\n",
      "9. hep-ph/9606272 - Gluon fragmentation function in polarised $\\Lambda$ hyperon ...\n",
      "10. 2109.05041 - On a novel evalutation of the hadronic contribution to the m...\n",
      "\n",
      "🔹 FAISS - Top 10 documentos:\n",
      "1. math-ph/0511087 - The Aharonov-Anandan phase of a classical dynamical system s...\n",
      "2. 1303.5471 - The Second Law of Thermodynamics under Unitary Evolution and...\n",
      "3. 2303.15645 - Triple Interference, Non-linear Talbot Effect and Gravitizat...\n",
      "4. 2309.01851 - Classical stochastic approach to quantum mechanics and quant...\n",
      "5. 1609.02265 - Defect production in nonequilibrium phase transitions: Exper...\n",
      "6. 1004.1214 - Oriented Quantum Algebras and Coalgebras, Invariants of Orie...\n",
      "7. 1707.05347 - A new duality between Topological M-theory and Loop Quantum ...\n",
      "8. 1704.06846 - Equation of State of Quantum Gases Beyond the Van der Waals\n",
      "...\n",
      "9. hep-th/9701022 - The Maxwell-Bloch Theory in Quantum Optics and the Kondo Mod...\n",
      "10. 1007.1656 - Orthogonal Quantum Group Invariants of Links...\n",
      "\n",
      " Comparación de coincidencias en el top 10:\n",
      "TF-IDF vs BM25: 2 en común → ['hep-lat/9712019', '1811.10085']\n",
      "TF-IDF vs FAISS: 0 en común → []\n",
      "BM25 vs FAISS: 0 en común → []\n",
      "\n",
      " Respuesta generada por RAG (CHAT GTP):\n",
      "Quantum Chromodynamics (QCD) es la teoría cuántica de las interacciones fuertes entre quarks y gluones, que son los constituyentes fundamentales de los hadrones, como los protones y neutrones. En el contexto de la física cuántica, QCD es fundamental para comprender la estructura de la materia a nivel subatómico y su interacción a través de las fuerzas nucleares fuertes.\n",
      "\n",
      "========================================================================================================================\n",
      "\n",
      " Consulta: higgs boson decay\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "🔹 TF-IDF - Top 10 documentos:\n",
      "1. 1311.7208 - A New Avenue to Charged Higgs Discovery in Multi-Higgs Model...\n",
      "2. hep-ph/9610541 - Production of a Higgs Boson Plus Two Jets in Hadronic Collis...\n",
      "3. 1306.0023 - Searches for the Higgs boson decaying to W^{+} W^{-} -> l^{+...\n",
      "4. 1202.2065 - Combined upper limit on Standard Model Higgs boson productio...\n",
      "5. 0809.4566 - Global Electroweak Fits and the Higgs Boson Mass...\n",
      "6. hep-ph/0502110 - Gluon-Gluon Antenna Functions from Higgs Boson Decay...\n",
      "7. 1304.6338 - Higgs sectors with exotic scalar fields...\n",
      "8. 1603.05910 - Reconstruction of the Higgs mass in events with Higgs bosons...\n",
      "9. hep-ph/9903360 - Measuring the Higgs Boson Yukawa Couplings at an NLC...\n",
      "10. 1401.3311 - Strong dynamics behind the formation of the $125$ GeV Higgs ...\n",
      "\n",
      "🔹 BM25 - Top 10 documentos:\n",
      "1. hep-ph/0502110 - Gluon-Gluon Antenna Functions from Higgs Boson Decay...\n",
      "2. 1112.6043 - Discrimination of the light CP-odd scalars between in the NM...\n",
      "3. hep-ph/9708292 - The order $O(\\bar{\\alpha}~\\bar{\\alpha}_s)$ and $O(\\bar{\\alph...\n",
      "4. 1306.0023 - Searches for the Higgs boson decaying to W^{+} W^{-} -> l^{+...\n",
      "5. 1311.7208 - A New Avenue to Charged Higgs Discovery in Multi-Higgs Model...\n",
      "6. 0802.1410 - HNNLO: a Monte Carlo program to compute Higgs boson producti...\n",
      "7. hep-ph/0407057 - Interference of Higgs boson resonances in mu^+ mu^- -> neutr...\n",
      "8. 0709.1029 - Four-lepton LHC events from MSSM Higgs boson decays into neu...\n",
      "9. hep-ph/0001194 - The triple Higgs self-coupling at future e+e- colliders: a\n",
      " ...\n",
      "10. 1211.6058 - Reconstructing the 125 GeV SM Higgs Boson Through $\\ell\\bar{...\n",
      "\n",
      "🔹 FAISS - Top 10 documentos:\n",
      "1. hep-ph/9310348 - Supersymmetric top decays...\n",
      "2. 1506.02718 - Revisiting the flavor changing neutral current Higgs decays ...\n",
      "3. 0710.4591 - Nonstandard Higgs Decays with Visible and Missing Energy...\n",
      "4. 1211.6058 - Reconstructing the 125 GeV SM Higgs Boson Through $\\ell\\bar{...\n",
      "5. 0709.1029 - Four-lepton LHC events from MSSM Higgs boson decays into neu...\n",
      "6. 1708.09050 - Top quark mass, spin and decay properties...\n",
      "7. 0712.2954 - Study of the exclusive $b \\to u \\ell^- \\bar{\\nu}_{\\ell}$ dec...\n",
      "8. 1508.01897 - Leptoquark induced rare decay amplitudes $h \\to \\tau^\\mp \\mu...\n",
      "9. 1401.3311 - Strong dynamics behind the formation of the $125$ GeV Higgs ...\n",
      "10. 2307.10361 - Higgs Criticality beyond the Standard Model...\n",
      "\n",
      " Comparación de coincidencias en el top 10:\n",
      "TF-IDF vs BM25: 3 en común → ['1311.7208', '1306.0023', 'hep-ph/0502110']\n",
      "TF-IDF vs FAISS: 1 en común → ['1401.3311']\n",
      "BM25 vs FAISS: 2 en común → ['1211.6058', '0709.1029']\n",
      "\n",
      " Respuesta generada por RAG (CHAT GTP):\n",
      "El decaimiento del bosón de Higgs es un proceso fundamental en la física de partículas, que puede ocurrir de diversas maneras dependiendo del modelo teórico en el que se esté trabajando. Algunos de los posibles modos de decaimiento incluyen la desintegración en partículas supersimétricas, en quarks a través de corrientes neutras de cambio de sabor, o en otras partículas más allá de las predichas por el Modelo Estándar. Estudiar y comprender los diferentes canales de decaimiento del bosón de Higgs es crucial para validar la teoría y buscar posibles extensiones más allá de ella.\n",
      "\n",
      "========================================================================================================================\n",
      "\n",
      " Consulta: machine learning for particle physics\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "🔹 TF-IDF - Top 10 documentos:\n",
      "1. 2211.08064 - Physics-Informed Machine Learning: A Survey on Problems, Met...\n",
      "2. 2006.16789 - Causality Learning: A New Perspective for Interpretable Mach...\n",
      "3. 2201.09345 - Machine Learning Symmetry...\n",
      "4. 1804.06913 - Fast inference of deep neural networks in FPGAs for particle...\n",
      "5. 2211.13210 - Community Engagement Frontier...\n",
      "6. 2405.01359 - GAIA: A General AI Assistant for Intelligent Accelerator Ope...\n",
      "7. 2111.04439 - Addressing Privacy Threats from Machine Learning...\n",
      "8. 2203.07946 - Snowmass2021 Theory Frontier White Paper: Data-Driven Cosmol...\n",
      "9. 1801.08830 - Bringing particle physics into classrooms...\n",
      "10. 2010.14236 - Scientific intuition inspired by machine learning generated ...\n",
      "\n",
      "🔹 BM25 - Top 10 documentos:\n",
      "1. 1804.06913 - Fast inference of deep neural networks in FPGAs for particle...\n",
      "2. 2211.08064 - Physics-Informed Machine Learning: A Survey on Problems, Met...\n",
      "3. 2405.01359 - GAIA: A General AI Assistant for Intelligent Accelerator Ope...\n",
      "4. 2010.14236 - Scientific intuition inspired by machine learning generated ...\n",
      "5. 2403.17436 - Particle identification with machine learning from incomplet...\n",
      "6. 2207.09060 - Data Science and Machine Learning in Education...\n",
      "7. 2506.09678 - Black hole/quantum machine learning correspondence...\n",
      "8. 2205.15122 - Digital quantum simulation of an extended Agassi model: Usin...\n",
      "9. 2211.13210 - Community Engagement Frontier...\n",
      "10. 2108.03125 - Beyond Cuts in Small Signal Scenarios -- Enhanced Sneutrino\n",
      "...\n",
      "\n",
      "🔹 FAISS - Top 10 documentos:\n",
      "1. 2403.17436 - Particle identification with machine learning from incomplet...\n",
      "2. 2311.06893 - Methods of machine learning for the analysis of cosmic rays ...\n",
      "3. 2006.14142 - Heuristic machinery for thermodynamic studies of SU(N) fermi...\n",
      "4. 2502.17597 - Unraveling particle dark matter with Physics-Informed Neural...\n",
      "5. 1708.07034 - Application of a Convolutional Neural Network for image clas...\n",
      "6. 2205.15122 - Digital quantum simulation of an extended Agassi model: Usin...\n",
      "7. 2108.03125 - Beyond Cuts in Small Signal Scenarios -- Enhanced Sneutrino\n",
      "...\n",
      "8. 2506.09678 - Black hole/quantum machine learning correspondence...\n",
      "9. 1904.10321 - Prediction of the Atomization Energy of Molecules Using Coul...\n",
      "10. 2506.11194 - Machine Learning Acceleration of Neutron Star Pulse Profile ...\n",
      "\n",
      " Comparación de coincidencias en el top 10:\n",
      "TF-IDF vs BM25: 5 en común → ['2211.13210', '2405.01359', '1804.06913', '2211.08064', '2010.14236']\n",
      "TF-IDF vs FAISS: 0 en común → []\n",
      "BM25 vs FAISS: 4 en común → ['2506.09678', '2108.03125', '2403.17436', '2205.15122']\n",
      "\n",
      " Respuesta generada por RAG (CHAT GTP):\n",
      "El uso de machine learning en física de partículas, como se menciona en los documentos citados, es fundamental para tareas como la identificación precisa de partículas en colisiones de iones pesados ultrarrelativistas y la reconstrucción de la composición de masas de rayos cósmicos de alta energía a partir de datos experimentales de lluvias atmosféricas extensas. La aplicación de técnicas de machine learning en estos contextos permite analizar mediciones experimentales con una sensibilidad sin precedentes, aunque aún existen desafíos para investigar los efectos sutiles relacionados directamente con observables físicos y comprender la física detrás de los experimentos ordinarios.\n",
      "\n",
      "========================================================================================================================\n",
      "\n",
      " Consulta: top quark production\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "🔹 TF-IDF - Top 10 documentos:\n",
      "1. 0901.1063 - Search for admixture of scalar top quarks in the ttbar lepto...\n",
      "2. gr-qc/0310079 - Restricting quark matter models by gravitational wave observ...\n",
      "3. 1611.04492 - Top physics at CLIC and ILC...\n",
      "4. 1004.1732 - Beyond the Standard Model searches with top quarks at D0...\n",
      "5. hep-ph/0412298 - The role of quark mass in cold and dense perturbative QCD...\n",
      "6. 2504.07897 - The Constituent Quark Model...\n",
      "7. hep-ph/9410270 - Table of Running Quark Mass Values : 1994...\n",
      "8. 1612.04009 - Wigner distributions of quarks for different polarizations...\n",
      "9. hep-ph/9709358 - On the Fragmentation Function for Heavy Quarks in e+e- colli...\n",
      "10. 1708.09050 - Top quark mass, spin and decay properties...\n",
      "\n",
      "🔹 BM25 - Top 10 documentos:\n",
      "1. 0901.1063 - Search for admixture of scalar top quarks in the ttbar lepto...\n",
      "2. 1004.1732 - Beyond the Standard Model searches with top quarks at D0...\n",
      "3. hep-ph/9507411 - Four Top Production and Electroweak Symmetry Breaking...\n",
      "4. hep-ph/9709358 - On the Fragmentation Function for Heavy Quarks in e+e- colli...\n",
      "5. 1203.2964 - Charmonium production from nonequilibrium charm and antichar...\n",
      "6. hep-ex/9810037 - On the observability of free quarks near their production th...\n",
      "7. 1808.03871 - Forward trijet production in proton-nucleus collisions...\n",
      "8. 1611.04492 - Top physics at CLIC and ILC...\n",
      "9. 1205.0760 - Effect of running coupling on photon emission from quark glu...\n",
      "10. hep-ph/9606272 - Gluon fragmentation function in polarised $\\Lambda$ hyperon ...\n",
      "\n",
      "🔹 FAISS - Top 10 documentos:\n",
      "1. hep-ex/9810037 - On the observability of free quarks near their production th...\n",
      "2. 2008.11133 - NNLO QCD corrections to leptonic observables in top-quark pa...\n",
      "3. 0808.1625 - Exclusive heavy quarkonium + gamma production from e+ e- ann...\n",
      "4. 2306.07788 - Quantum Entanglement in Top Quark Pair Production...\n",
      "5. 1611.04492 - Top physics at CLIC and ILC...\n",
      "6. 1812.07343 - Search for single production of vector-like quarks decaying ...\n",
      "7. 1302.3628 - Top Quark Physics at the Tevatron...\n",
      "8. 0901.1063 - Search for admixture of scalar top quarks in the ttbar lepto...\n",
      "9. 0802.2621 - Search for 4th family quarks with the ATLAS detector...\n",
      "10. 2404.06829 - Electroweak, QCD and flavour physics studies with ATLAS data...\n",
      "\n",
      " Comparación de coincidencias en el top 10:\n",
      "TF-IDF vs BM25: 4 en común → ['1611.04492', 'hep-ph/9709358', '0901.1063', '1004.1732']\n",
      "TF-IDF vs FAISS: 2 en común → ['1611.04492', '0901.1063']\n",
      "BM25 vs FAISS: 3 en común → ['hep-ex/9810037', '1611.04492', '0901.1063']\n",
      "\n",
      " Respuesta generada por RAG (CHAT GTP):\n",
      "La producción del quark top es un proceso fundamental en la física de partículas, que involucra la creación de pares de quarks top y antitop. Se han realizado estudios para investigar las correlaciones de espín y las distribuciones diferenciales en la producción y desintegración de pares de quarks top en estados finales dileptónicos. Además, se han analizado las secciones eficaces para la producción exclusiva de fotones asociados con quarkonium pesado en colisiones de e+ e-. Estos estudios proporcionan información importante sobre la física de altas energías y la interacción de partículas subatómicas.\n",
      "\n",
      "========================================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"queries.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    queries = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# Función para extraer solo los IDs del top-k\n",
    "def extract_ids(results):\n",
    "    return [r[\"id\"] for r in results]\n",
    "\n",
    "# Procesar cada consulta\n",
    "for query in queries:\n",
    "    print(f\" Consulta: {query}\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    tfidf_results = search_tfidf(query)\n",
    "    bm25_results = search_bm25(query)\n",
    "    faiss_results = search_faiss(query)\n",
    "    rag_response = generate_rag_response_openai(query)\n",
    "\n",
    "    # Mostrar top 10 resultados\n",
    "    for name, results in zip([\"TF-IDF\", \"BM25\", \"FAISS\"], [tfidf_results, bm25_results, faiss_results]):\n",
    "        print(f\"\\n🔹 {name} - Top 10 documentos:\")\n",
    "        for i, r in enumerate(results, 1):\n",
    "            print(f\"{i}. {r['id']} - {r['title'][:60]}...\")\n",
    "\n",
    "    # Extraer IDs\n",
    "    tfidf_ids = extract_ids(tfidf_results)\n",
    "    bm25_ids = extract_ids(bm25_results)\n",
    "    faiss_ids = extract_ids(faiss_results)\n",
    "\n",
    "    # Comparaciones\n",
    "    tfidf_vs_bm25 = list(set(tfidf_ids) & set(bm25_ids))\n",
    "    tfidf_vs_faiss = list(set(tfidf_ids) & set(faiss_ids))\n",
    "    bm25_vs_faiss = list(set(bm25_ids) & set(faiss_ids))\n",
    "\n",
    "    # Mostrar comparaciones\n",
    "    print(\"\\n Comparación de coincidencias en el top 10:\")\n",
    "    print(f\"TF-IDF vs BM25: {len(tfidf_vs_bm25)} en común → {tfidf_vs_bm25}\")\n",
    "    print(f\"TF-IDF vs FAISS: {len(tfidf_vs_faiss)} en común → {tfidf_vs_faiss}\")\n",
    "    print(f\"BM25 vs FAISS: {len(bm25_vs_faiss)} en común → {bm25_vs_faiss}\")\n",
    "\n",
    "    # Mostrar respuesta RAG\n",
    "    print(\"\\n Respuesta generada por RAG (CHAT GTP):\")\n",
    "    print(rag_response)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 120 + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
