{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84973f3b9d53059",
   "metadata": {},
   "source": [
    "# Ejercicio 13: LangChain\n",
    "\n",
    "LangChain es un _framework_ de código abierto diseñado para facilitar el desarrollo de aplicaciones que combinan modelos de lenguaje LLMs con datos, herramientas externas y memoria. Está especialmente pensado para construir aplicaciones complejas basadas en IA, como sistemas _Retrieval-Augmented Generation_, asistentes conversacionales inteligentes, agentes autónomos y sistemas con razonamiento compuesto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e0e6d4008e622",
   "metadata": {},
   "source": [
    "## Parte 1: Carga y preprocesamiento del corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7779ec483e8993e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/rajneesh231/lex-fridman-podcast-transcript\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import kaggle\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar variables de entorno desde .env\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"KAGGLE_USERNAME\"] = os.getenv(\"KAGGLE_USERNAME\")\n",
    "os.environ[\"KAGGLE_KEY\"] = os.getenv(\"KAGGLE_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# Descargar el dataset (si no existe)\n",
    "dataset = \"rajneesh231/lex-fridman-podcast-transcript\"\n",
    "path = \"../data/13langchain\"\n",
    "\n",
    "kaggle.api.dataset_download_files(dataset, path=path, unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d386c15c68427b6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T16:15:07.098935Z",
     "start_time": "2025-07-23T16:15:06.650753Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>guest</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Max Tegmark</td>\n",
       "      <td>Life 3.0</td>\n",
       "      <td>As part of MIT course 6S099, Artificial Genera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Christof Koch</td>\n",
       "      <td>Consciousness</td>\n",
       "      <td>As part of MIT course 6S099 on artificial gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Steven Pinker</td>\n",
       "      <td>AI in the Age of Reason</td>\n",
       "      <td>You've studied the human mind, cognition, lang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Yoshua Bengio</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>What difference between biological neural netw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Vladimir Vapnik</td>\n",
       "      <td>Statistical Learning</td>\n",
       "      <td>The following is a conversation with Vladimir ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>321</td>\n",
       "      <td>Ray Kurzweil</td>\n",
       "      <td>Singularity, Superintelligence, and Immortality</td>\n",
       "      <td>By the time he gets to 2045, we'll be able to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>322</td>\n",
       "      <td>Rana el Kaliouby</td>\n",
       "      <td>Emotion AI, Social Robots, and Self-Driving Cars</td>\n",
       "      <td>there's a broader question here, right? As we ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>323</td>\n",
       "      <td>Will Sasso</td>\n",
       "      <td>Comedy, MADtv, AI, Friendship, Madness, and Pr...</td>\n",
       "      <td>Once this whole thing falls apart and we are c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>324</td>\n",
       "      <td>Daniel Negreanu</td>\n",
       "      <td>Poker</td>\n",
       "      <td>you could be the seventh best player in the wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>325</td>\n",
       "      <td>Michael Levin</td>\n",
       "      <td>Biology, Life, Aliens, Evolution, Embryogenesi...</td>\n",
       "      <td>turns out that if you train a planarian and th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>319 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id             guest                                              title  \\\n",
       "0      1       Max Tegmark                                           Life 3.0   \n",
       "1      2     Christof Koch                                      Consciousness   \n",
       "2      3     Steven Pinker                            AI in the Age of Reason   \n",
       "3      4     Yoshua Bengio                                      Deep Learning   \n",
       "4      5   Vladimir Vapnik                               Statistical Learning   \n",
       "..   ...               ...                                                ...   \n",
       "314  321      Ray Kurzweil    Singularity, Superintelligence, and Immortality   \n",
       "315  322  Rana el Kaliouby   Emotion AI, Social Robots, and Self-Driving Cars   \n",
       "316  323        Will Sasso  Comedy, MADtv, AI, Friendship, Madness, and Pr...   \n",
       "317  324   Daniel Negreanu                                              Poker   \n",
       "318  325     Michael Levin  Biology, Life, Aliens, Evolution, Embryogenesi...   \n",
       "\n",
       "                                                  text  \n",
       "0    As part of MIT course 6S099, Artificial Genera...  \n",
       "1    As part of MIT course 6S099 on artificial gene...  \n",
       "2    You've studied the human mind, cognition, lang...  \n",
       "3    What difference between biological neural netw...  \n",
       "4    The following is a conversation with Vladimir ...  \n",
       "..                                                 ...  \n",
       "314  By the time he gets to 2045, we'll be able to ...  \n",
       "315  there's a broader question here, right? As we ...  \n",
       "316  Once this whole thing falls apart and we are c...  \n",
       "317  you could be the seventh best player in the wh...  \n",
       "318  turns out that if you train a planarian and th...  \n",
       "\n",
       "[319 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar el dataset CSV\n",
    "file_path = os.path.join(path, \"podcastdata_dataset.csv\")  # ajusta nombre si difiere\n",
    "df = pd.read_csv(file_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d2b1fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.26-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.66 (from langchain)\n",
      "  Downloading langchain_core-0.3.71-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.4.8-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.66->langchain)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.66->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\gboy2\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (4.14.0)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\gboy2\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (25.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading orjson-3.11.0-cp311-cp311-win_amd64.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/43.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/43.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/43.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 43.1/43.1 kB ? eta 0:00:00\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading zstandard-0.23.0-cp311-cp311-win_amd64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (2025.6.15)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
      "Requirement already satisfied: anyio in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
      "Downloading langchain-0.3.26-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.0/1.0 MB 325.1 kB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.0/1.0 MB 326.8 kB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.1/1.0 MB 409.6 kB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.1/1.0 MB 381.3 kB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.1/1.0 MB 403.5 kB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.1/1.0 MB 409.6 kB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.1/1.0 MB 379.3 kB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 0.1/1.0 MB 387.0 kB/s eta 0:00:03\n",
      "   ------ --------------------------------- 0.2/1.0 MB 403.5 kB/s eta 0:00:03\n",
      "   ------- -------------------------------- 0.2/1.0 MB 420.8 kB/s eta 0:00:02\n",
      "   -------- ------------------------------- 0.2/1.0 MB 401.2 kB/s eta 0:00:03\n",
      "   -------- ------------------------------- 0.2/1.0 MB 405.0 kB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 0.3/1.0 MB 413.7 kB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 0.3/1.0 MB 415.4 kB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 0.3/1.0 MB 421.5 kB/s eta 0:00:02\n",
      "   ------------ --------------------------- 0.3/1.0 MB 422.4 kB/s eta 0:00:02\n",
      "   ------------- -------------------------- 0.3/1.0 MB 427.8 kB/s eta 0:00:02\n",
      "   -------------- ------------------------- 0.4/1.0 MB 428.2 kB/s eta 0:00:02\n",
      "   -------------- ------------------------- 0.4/1.0 MB 424.6 kB/s eta 0:00:02\n",
      "   --------------- ------------------------ 0.4/1.0 MB 433.0 kB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 0.4/1.0 MB 436.7 kB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 0.4/1.0 MB 436.6 kB/s eta 0:00:02\n",
      "   ------------------ --------------------- 0.5/1.0 MB 446.9 kB/s eta 0:00:02\n",
      "   ------------------- -------------------- 0.5/1.0 MB 446.5 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 0.5/1.0 MB 455.1 kB/s eta 0:00:02\n",
      "   --------------------- ------------------ 0.5/1.0 MB 445.6 kB/s eta 0:00:02\n",
      "   --------------------- ------------------ 0.6/1.0 MB 451.1 kB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 0.6/1.0 MB 456.0 kB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 0.6/1.0 MB 455.6 kB/s eta 0:00:01\n",
      "   ------------------------ --------------- 0.6/1.0 MB 460.1 kB/s eta 0:00:01\n",
      "   ------------------------- -------------- 0.6/1.0 MB 456.4 kB/s eta 0:00:01\n",
      "   -------------------------- ------------- 0.7/1.0 MB 466.1 kB/s eta 0:00:01\n",
      "   --------------------------- ------------ 0.7/1.0 MB 467.0 kB/s eta 0:00:01\n",
      "   --------------------------- ------------ 0.7/1.0 MB 459.3 kB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 0.7/1.0 MB 463.3 kB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 0.7/1.0 MB 467.2 kB/s eta 0:00:01\n",
      "   ------------------------------ --------- 0.8/1.0 MB 468.0 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 0.8/1.0 MB 465.5 kB/s eta 0:00:01\n",
      "   -------------------------------- ------- 0.8/1.0 MB 472.2 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 0.8/1.0 MB 469.7 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 0.9/1.0 MB 470.5 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 0.9/1.0 MB 473.5 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 0.9/1.0 MB 476.5 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 0.9/1.0 MB 477.1 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.0/1.0 MB 468.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 480.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 478.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 474.9 kB/s eta 0:00:00\n",
      "Downloading langchain_core-0.3.71-py3-none-any.whl (442 kB)\n",
      "   ---------------------------------------- 0.0/442.8 kB ? eta -:--:--\n",
      "    --------------------------------------- 10.2/442.8 kB ? eta -:--:--\n",
      "   --- ----------------------------------- 41.0/442.8 kB 495.5 kB/s eta 0:00:01\n",
      "   ----- --------------------------------- 61.4/442.8 kB 544.7 kB/s eta 0:00:01\n",
      "   -------- ------------------------------ 92.2/442.8 kB 525.1 kB/s eta 0:00:01\n",
      "   ---------- --------------------------- 122.9/442.8 kB 514.3 kB/s eta 0:00:01\n",
      "   ------------ ------------------------- 143.4/442.8 kB 568.9 kB/s eta 0:00:01\n",
      "   -------------- ----------------------- 174.1/442.8 kB 551.6 kB/s eta 0:00:01\n",
      "   ---------------- --------------------- 194.6/442.8 kB 562.0 kB/s eta 0:00:01\n",
      "   ------------------- ------------------ 225.3/442.8 kB 550.0 kB/s eta 0:00:01\n",
      "   --------------------- ---------------- 245.8/442.8 kB 558.1 kB/s eta 0:00:01\n",
      "   ----------------------- -------------- 276.5/442.8 kB 567.7 kB/s eta 0:00:01\n",
      "   ------------------------ ------------- 286.7/442.8 kB 553.0 kB/s eta 0:00:01\n",
      "   -------------------------- ----------- 307.2/442.8 kB 559.2 kB/s eta 0:00:01\n",
      "   -------------------------- ----------- 307.2/442.8 kB 559.2 kB/s eta 0:00:01\n",
      "   -------------------------- ----------- 307.2/442.8 kB 559.2 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 389.1/442.8 kB 563.8 kB/s eta 0:00:01\n",
      "   ----------------------------------- -- 409.6/442.8 kB 555.4 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 419.8/442.8 kB 534.7 kB/s eta 0:00:01\n",
      "   -------------------------------------- 442.8/442.8 kB 532.7 kB/s eta 0:00:00\n",
      "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading langsmith-0.4.8-py3-none-any.whl (367 kB)\n",
      "   ---------------------------------------- 0.0/368.0 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/368.0 kB ? eta -:--:--\n",
      "   ---- ---------------------------------- 41.0/368.0 kB 487.6 kB/s eta 0:00:01\n",
      "   ------ -------------------------------- 61.4/368.0 kB 544.7 kB/s eta 0:00:01\n",
      "   ------- ------------------------------- 71.7/368.0 kB 435.7 kB/s eta 0:00:01\n",
      "   --------- ----------------------------- 92.2/368.0 kB 476.3 kB/s eta 0:00:01\n",
      "   ------------ ------------------------- 122.9/368.0 kB 450.6 kB/s eta 0:00:01\n",
      "   -------------- ----------------------- 143.4/368.0 kB 472.1 kB/s eta 0:00:01\n",
      "   --------------- ---------------------- 153.6/368.0 kB 482.7 kB/s eta 0:00:01\n",
      "   -------------------- ----------------- 194.6/368.0 kB 491.5 kB/s eta 0:00:01\n",
      "   --------------------- ---------------- 204.8/368.0 kB 478.0 kB/s eta 0:00:01\n",
      "   ----------------------- -------------- 225.3/368.0 kB 491.0 kB/s eta 0:00:01\n",
      "   ------------------------ ------------- 235.5/368.0 kB 480.3 kB/s eta 0:00:01\n",
      "   ---------------------------- --------- 276.5/368.0 kB 486.7 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 286.7/368.0 kB 491.1 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 317.4/368.0 kB 479.3 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 337.9/368.0 kB 498.8 kB/s eta 0:00:01\n",
      "   -------------------------------------- 368.0/368.0 kB 486.7 kB/s eta 0:00:00\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading orjson-3.11.0-cp311-cp311-win_amd64.whl (129 kB)\n",
      "   ---------------------------------------- 0.0/129.3 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 10.2/129.3 kB ? eta -:--:--\n",
      "   ------------ -------------------------- 41.0/129.3 kB 991.0 kB/s eta 0:00:01\n",
      "   ------------------ -------------------- 61.4/129.3 kB 550.5 kB/s eta 0:00:01\n",
      "   --------------------------- ----------- 92.2/129.3 kB 655.4 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 112.6/129.3 kB 595.3 kB/s eta 0:00:01\n",
      "   -------------------------------------- 129.3/129.3 kB 586.7 kB/s eta 0:00:00\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "   ---------------------------------------- 0.0/54.5 kB ? eta -:--:--\n",
      "   ------- -------------------------------- 10.2/54.5 kB ? eta -:--:--\n",
      "   ------------------------------ --------- 41.0/54.5 kB 487.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 54.5/54.5 kB 470.6 kB/s eta 0:00:00\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading zstandard-0.23.0-cp311-cp311-win_amd64.whl (495 kB)\n",
      "   ---------------------------------------- 0.0/495.4 kB ? eta -:--:--\n",
      "    --------------------------------------- 10.2/495.4 kB ? eta -:--:--\n",
      "   --- ----------------------------------- 41.0/495.4 kB 667.8 kB/s eta 0:00:01\n",
      "   ---- ---------------------------------- 61.4/495.4 kB 550.5 kB/s eta 0:00:01\n",
      "   ------- ------------------------------- 92.2/495.4 kB 585.1 kB/s eta 0:00:01\n",
      "   ------- ------------------------------ 102.4/495.4 kB 538.9 kB/s eta 0:00:01\n",
      "   ---------- --------------------------- 143.4/495.4 kB 610.6 kB/s eta 0:00:01\n",
      "   ----------- -------------------------- 153.6/495.4 kB 541.0 kB/s eta 0:00:01\n",
      "   -------------- ----------------------- 184.3/495.4 kB 557.9 kB/s eta 0:00:01\n",
      "   --------------- ---------------------- 204.8/495.4 kB 567.2 kB/s eta 0:00:01\n",
      "   ----------------- -------------------- 225.3/495.4 kB 573.4 kB/s eta 0:00:01\n",
      "   ------------------- ------------------ 256.0/495.4 kB 605.3 kB/s eta 0:00:01\n",
      "   --------------------- ---------------- 286.7/495.4 kB 571.2 kB/s eta 0:00:01\n",
      "   ----------------------- -------------- 307.2/495.4 kB 593.9 kB/s eta 0:00:01\n",
      "   ------------------------- ------------ 337.9/495.4 kB 583.1 kB/s eta 0:00:01\n",
      "   -------------------------- ----------- 348.2/495.4 kB 584.6 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 389.1/495.4 kB 592.0 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 419.8/495.4 kB 596.2 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 430.1/495.4 kB 584.7 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 471.0/495.4 kB 590.0 kB/s eta 0:00:01\n",
      "   -------------------------------------  491.5/495.4 kB 581.3 kB/s eta 0:00:01\n",
      "   -------------------------------------- 495.4/495.4 kB 586.0 kB/s eta 0:00:00\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Installing collected packages: zstandard, tenacity, orjson, jsonpointer, requests-toolbelt, jsonpatch, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "Successfully installed jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.26 langchain-core-0.3.71 langchain-text-splitters-0.3.8 langsmith-0.4.8 orjson-3.11.0 requests-toolbelt-1.0.0 tenacity-9.1.2 zstandard-0.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T16:18:05.558437Z",
     "start_time": "2025-07-23T16:18:05.535833Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "# Convertir cada fila en un Document\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=row[\"text\"],\n",
    "        metadata={\"id\": row[\"id\"], \"guest\": row[\"guest\"], \"title\": row[\"title\"]},\n",
    "    )\n",
    "    for _, row in df.iterrows()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a9bc525e775bbb",
   "metadata": {},
   "source": [
    "## Parte 2: Segmentación y embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "695f036cad73f49d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T16:21:20.197433Z",
     "start_time": "2025-07-23T16:21:12.798222Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fbdd150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community) (0.3.71)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community) (0.3.26)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community) (6.0.2)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
      "  Downloading aiohttp-3.12.14-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community) (9.1.2)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community) (0.4.8)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community) (2.2.6)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading frozenlist-1.7.0-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading multidict-6.6.3-cp311-cp311-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading propcache-0.3.2-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading yarl-1.20.1-cp311-cp311-win_amd64.whl.metadata (76 kB)\n",
      "     ---------------------------------------- 0.0/76.3 kB ? eta -:--:--\n",
      "     -------------------- ----------------- 41.0/76.3 kB 991.0 kB/s eta 0:00:01\n",
      "     ------------------------------ ------- 61.4/76.3 kB 656.4 kB/s eta 0:00:01\n",
      "     -------------------------------------- 76.3/76.3 kB 606.3 kB/s eta 0:00:00\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (2.11.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\gboy2\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (4.14.0)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\gboy2\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (25.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (3.11.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain-community) (2025.6.15)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.3)\n",
      "Requirement already satisfied: anyio in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (2.33.2)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\n",
      "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/2.5 MB 7.0 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 0.1/2.5 MB 1.7 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.4/2.5 MB 2.9 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 0.4/2.5 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.8/2.5 MB 3.4 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.9/2.5 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.4/2.5 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 2.0/2.5 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.5/2.5 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.5/2.5 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.5/2.5 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 4.7 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.12.14-cp311-cp311-win_amd64.whl (452 kB)\n",
      "   ---------------------------------------- 0.0/452.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 452.3/452.3 kB 14.3 MB/s eta 0:00:00\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "   ---------------------------------------- 0.0/45.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 45.2/45.2 kB ? eta 0:00:00\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "   ---------------------------------------- 0.0/63.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 63.8/63.8 kB ? eta 0:00:00\n",
      "Downloading frozenlist-1.7.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 44.0/44.0 kB 2.1 MB/s eta 0:00:00\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.9/50.9 kB 2.7 MB/s eta 0:00:00\n",
      "Downloading multidict-6.6.3-cp311-cp311-win_amd64.whl (45 kB)\n",
      "   ---------------------------------------- 0.0/45.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 45.9/45.9 kB 2.4 MB/s eta 0:00:00\n",
      "Downloading propcache-0.3.2-cp311-cp311-win_amd64.whl (41 kB)\n",
      "   ---------------------------------------- 0.0/41.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 41.5/41.5 kB 2.1 MB/s eta 0:00:00\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.20.1-cp311-cp311-win_amd64.whl (86 kB)\n",
      "   ---------------------------------------- 0.0/86.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 86.7/86.7 kB 4.8 MB/s eta 0:00:00\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Installing collected packages: propcache, mypy-extensions, multidict, marshmallow, httpx-sse, frozenlist, attrs, aiohappyeyeballs, yarl, typing-inspect, aiosignal, pydantic-settings, dataclasses-json, aiohttp, langchain-community\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.14 aiosignal-1.4.0 attrs-25.3.0 dataclasses-json-0.6.7 frozenlist-1.7.0 httpx-sse-0.4.1 langchain-community-0.3.27 marshmallow-3.26.1 multidict-6.6.3 mypy-extensions-1.1.0 propcache-0.3.2 pydantic-settings-2.10.1 typing-inspect-0.9.0 yarl-1.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f37d277c221d8d62",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-07-23T16:22:36.189344Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gboy2\\AppData\\Local\\Temp\\ipykernel_7416\\2116709975.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "c:\\Users\\gboy2\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "texts = [chunk.page_content for chunk in chunks]\n",
    "vectorstore = FAISS.from_texts(texts, embeddings)\n",
    "\n",
    "vectorstore.save_local(\"index_13langchain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f90a244d7365130",
   "metadata": {},
   "source": [
    "## Parte 3: Indexación en FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c25d8b4093a7a977",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_texts(texts, embeddings)\n",
    "vectorstore.save_local(\"index_13langchain_02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb74ae073498f49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-gecko-001 ['embedText', 'countTextTokens']\n",
      "models/gemini-1.0-pro-vision-latest ['generateContent', 'countTokens']\n",
      "models/gemini-pro-vision ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-pro-latest ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-pro-002 ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-1.5-pro ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-latest ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-002 ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-1.5-flash-8b ['createCachedContent', 'generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-8b-001 ['createCachedContent', 'generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-8b-latest ['createCachedContent', 'generateContent', 'countTokens']\n",
      "models/gemini-2.5-pro-preview-03-25 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-preview-05-20 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-lite-preview-06-17 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-pro-preview-05-06 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-pro-preview-06-05 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-pro ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-exp ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.0-flash ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-001 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-exp-image-generation ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.0-flash-lite-001 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-lite ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-preview-image-generation ['generateContent', 'countTokens']\n",
      "models/gemini-2.0-flash-lite-preview-02-05 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-lite-preview ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-pro-exp ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-pro-exp-02-05 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-exp-1206 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-thinking-exp-01-21 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-thinking-exp ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-thinking-exp-1219 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-preview-tts ['countTokens', 'generateContent']\n",
      "models/gemini-2.5-pro-preview-tts ['countTokens', 'generateContent']\n",
      "models/learnlm-2.0-flash-experimental ['generateContent', 'countTokens']\n",
      "models/gemma-3-1b-it ['generateContent', 'countTokens']\n",
      "models/gemma-3-4b-it ['generateContent', 'countTokens']\n",
      "models/gemma-3-12b-it ['generateContent', 'countTokens']\n",
      "models/gemma-3-27b-it ['generateContent', 'countTokens']\n",
      "models/gemma-3n-e4b-it ['generateContent', 'countTokens']\n",
      "models/gemma-3n-e2b-it ['generateContent', 'countTokens']\n",
      "models/gemini-2.5-flash-lite ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/embedding-001 ['embedContent']\n",
      "models/text-embedding-004 ['embedContent']\n",
      "models/gemini-embedding-exp-03-07 ['embedContent', 'countTextTokens', 'countTokens']\n",
      "models/gemini-embedding-exp ['embedContent', 'countTextTokens', 'countTokens']\n",
      "models/gemini-embedding-001 ['embedContent', 'countTextTokens', 'countTokens']\n",
      "models/aqa ['generateAnswer']\n",
      "models/imagen-3.0-generate-002 ['predict']\n",
      "models/imagen-4.0-generate-preview-06-06 ['predict']\n",
      "models/imagen-4.0-ultra-generate-preview-06-06 ['predict']\n",
      "models/veo-2.0-generate-001 ['predictLongRunning']\n",
      "models/veo-3.0-generate-preview ['predictLongRunning']\n",
      "models/gemini-2.5-flash-preview-native-audio-dialog ['countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.5-flash-exp-native-audio-thinking-dialog ['countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.0-flash-live-001 ['bidiGenerateContent', 'countTokens']\n",
      "models/gemini-live-2.5-flash-preview ['bidiGenerateContent', 'countTokens']\n",
      "models/gemini-2.5-flash-live-preview ['bidiGenerateContent', 'countTokens']\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "for m in genai.list_models():\n",
    "    print(m.name, m.supported_generation_methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b4f87820f4355b",
   "metadata": {},
   "source": [
    "## Parte 4: Creación de la cadena de recuperación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3606309c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-google-genai\n",
      "  Downloading langchain_google_genai-2.1.8-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai)\n",
      "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.68 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-google-genai) (0.3.71)\n",
      "Requirement already satisfied: pydantic<3,>=2 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-google-genai) (2.11.7)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.25.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.40.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.29.5)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.4.8)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\gboy2\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (4.14.0)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\gboy2\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=2->langchain-google-genai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=2->langchain-google-genai) (0.4.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.32.4)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.73.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (3.11.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.16.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\gboy2\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.3.1)\n",
      "Downloading langchain_google_genai-2.1.8-py3-none-any.whl (47 kB)\n",
      "   ---------------------------------------- 0.0/47.8 kB ? eta -:--:--\n",
      "   -------- ------------------------------- 10.2/47.8 kB ? eta -:--:--\n",
      "   ------------------------- -------------- 30.7/47.8 kB 435.7 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 41.0/47.8 kB 326.8 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 47.8/47.8 kB 344.5 kB/s eta 0:00:00\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/1.4 MB 1.3 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 0.1/1.4 MB 1.3 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.2/1.4 MB 1.3 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.2/1.4 MB 1.4 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.3/1.4 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.5/1.4 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.5/1.4 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 0.9/1.4 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.0/1.4 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.4/1.4 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 3.2 MB/s eta 0:00:00\n",
      "Installing collected packages: filetype, google-ai-generativelanguage, langchain-google-genai\n",
      "  Attempting uninstall: google-ai-generativelanguage\n",
      "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
      "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
      "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
      "Successfully installed filetype-1.2.0 google-ai-generativelanguage-0.6.18 langchain-google-genai-2.1.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script filetype.exe is installed in 'c:\\Users\\gboy2\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "188db8cd884593de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gboy2\\AppData\\Local\\Temp\\ipykernel_7416\\1339226018.py:14: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = qa_chain.run(\"What is AGI Artificial General Intelligence?\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided text, AGI, or Artificial General Intelligence, is a type of AI with the ability to learn and adapt to new environments.  However, it's unclear if a machine with AGI would necessarily have consciousness.  The text also points out that the term is widely used and understood, even though its precise definition is debated, with some considering it simply very smart AI surpassing human intelligence, while others equate it to human-like intelligence.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Inicializar Gemini LLM\n",
    "llm = ChatGoogleGenerativeAI(model=\"models/gemini-1.5-flash\", temperature=0)\n",
    "\n",
    "# Crear retriever desde tu índice vectorial (FAISS o Chroma)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Cadena de pregunta-respuesta\n",
    "qa_chain = RetrievalQA.from_chain_type(llm, retriever=retriever)\n",
    "\n",
    "# Ejecutar una pregunta\n",
    "response = qa_chain.run(\"What is AGI Artificial General Intelligence?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92245802750b5009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No encontré información suficiente en el corpus.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "Usa solo el siguiente contexto para responder a la pregunta.\n",
    "Si la respuesta no está explícita en el contexto, responde exactamente:\n",
    "\"No encontré información suficiente en el corpus.\"\n",
    "\n",
    "Contexto:\n",
    "{context}\n",
    "\n",
    "Pregunta: {question}\n",
    "Respuesta:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")\n",
    "\n",
    "result = qa_chain.invoke({\"query\": \"¿Qué es AGI Artificial General Intelligence?\"})\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "702e8b3a3c62f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided text, AGI (Artificial General Intelligence) is a term used to describe artificial intelligence that reaches or surpasses human-level intelligence.  However, the text also notes that the term is not well-defined and that human intelligence itself is not truly \"general\" but rather highly specialized.  The text mentions AIXI as an example of a theoretical system that could be considered truly general intelligence within the constraints of computational theory.  There's no single agreed-upon test to definitively determine if AGI has been achieved.\n",
      "[Document(id='c3610ad7-05af-43f1-9d2a-7e07cd29a923', metadata={}, page_content=\"general intelligence, artificial intelligence, only refers to if you achieve human level or a subhuman level, but quite broad, is it also general intelligence? So we have to distinguish, or it's only super human intelligence, general artificial intelligence. Is there a test in your mind, like the Turing test for natural language or some other test that would impress the heck out of you that would kind of cross the line of your sense of intelligence within the framework that you said? Well, the\"), Document(id='72e53c3c-ceaf-4c3c-ab97-920f60852d41', metadata={}, page_content=\"but that's a different distinction. Then it should be engineered general intelligence, right? And then general, well, if you look at Marcus Hooter's book, universally, what he argues there is, within the domain of computation theory, which is limited, but interesting. So if you assume computable environments or computable reward functions, then he articulates what would be a truly general intelligence, a system called AIXI, which is quite beautiful. AIXI, and that's the middle name of my latest\"), Document(id='574173c3-79cb-40e6-9132-6293920b03f5', metadata={}, page_content=\"bit about the Turing test, StarCraft. All of these have echoes of general intelligence. But if you think about just something that you would sit back and say, wow, this is really something that resembles human level intelligence. What do you think it takes to build that? So I find that AGI oftentimes is maybe not very well defined. So what I'm trying to then come up with for myself is what would be a result look like that you would start to believe that you would have agents or neural nets that\"), Document(id='a426bf33-62a8-4151-9a6e-e89cd1a18bba', metadata={}, page_content=\"have games, things like that. So that's where the field is going really, this kind of environment. Now, back to the question of AGI. I don't like the term AGI because it implies that human intelligence is general and human intelligence is nothing like general. It's very, very specialized. We think it's general. We'd like to think of ourselves as having general intelligence. We don't, we're very specialized. We're only slightly more general than. Why does it feel general? So you kind of, the\")]\n"
     ]
    }
   ],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "result = qa_chain.invoke({\"query\": \"¿Qué es AGI Artificial General Intelligence?\"})\n",
    "print(result[\"result\"])\n",
    "print(result[\"source_documents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dade5f0b3a5d2a10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
